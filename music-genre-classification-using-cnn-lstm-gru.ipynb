{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\n\nimport os\nfrom PIL import Image\nfrom pathlib import Path\nimport csv\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\nimport tensorflow as tf\nimport librosa.display\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-11T18:20:37.944355Z","iopub.execute_input":"2023-08-11T18:20:37.945400Z","iopub.status.idle":"2023-08-11T18:20:43.264836Z","shell.execute_reply.started":"2023-08-11T18:20:37.945357Z","shell.execute_reply":"2023-08-11T18:20:43.263819Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"songname = f'../input/gtzan-genre-collection/genres/blues/blues.00000.au'\ny, sr = librosa.load(songname, mono=True, duration=2, offset=0)\nps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=256, n_fft=512, n_mels=128)\nps = librosa.power_to_db(ps**2)\nps.shape\n\ndataset = []\ngenres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, \n          'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n\nfor genre, genre_number in genres.items():\n    for filename in os.listdir(f'../input/gtzan-genre-collection/genres/{genre}'):\n        songname = f'../input/gtzan-genre-collection/genres/{genre}/{filename}'\n        for index in range(14):\n            y, sr = librosa.load(songname, mono=True, duration=2, offset=index*2)\n            ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length=256, n_fft=512, n_mels=64)\n            ps = librosa.power_to_db(ps**2)\n            dataset.append((ps, genre_number))\n\nprint(len(dataset))\nimport random\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-11T18:20:43.266388Z","iopub.execute_input":"2023-08-11T18:20:43.267117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.shuffle(dataset)\n\ntrain = dataset[:10000]\nvalid = dataset[10000:12000]\ntest = dataset[12000:]\n\nX_train, Y_train = zip(*train)\nX_valid, Y_valid = zip(*valid)\nX_test, Y_test = zip(*test)\n\n# Reshape for CNN input\nX_train = np.array([x.reshape((64, 173, 1)) for x in X_train])\nX_valid = np.array([x.reshape((64, 173, 1)) for x in X_valid])\nX_test = np.array([x.reshape((64, 173, 1)) for x in X_test])\n\n# One-Hot encoding for classes\nY_train = np.array(tf.keras.utils.to_categorical(Y_train, 10))\nY_valid = np.array(tf.keras.utils.to_categorical(Y_valid, 10))\nY_test = np.array(tf.keras.utils.to_categorical(Y_test, 10))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n\nlstm_model = Sequential([\n    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n    MaxPooling1D(pool_size=2),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Conv1D(filters=128, kernel_size=3, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Conv1D(filters=256, kernel_size=3, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Bidirectional(LSTM(128, return_sequences=True)),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Bidirectional(LSTM(64, return_sequences=True)),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    LSTM(32),\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Dense(10, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ngru_model = tf.keras.Sequential([\n    tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GRU(256, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GRU(128, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GRU(64, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GRU(32, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GRU(16, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Updated CNN Model with Batch Normalization, Dropout, L2 Regularization, and Learning Rate Schedule\ncnn_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 173, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile models\n# Use a learning rate schedule to gradually decrease the learning rate\nlstm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.2), loss=\"categorical_crossentropy\", metrics=['accuracy'])\ngru_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.2), loss=\"categorical_crossentropy\", metrics=['accuracy'])\ncnn_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.2), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training models\nlstm_history = lstm_model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_data=(X_valid, Y_valid))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gru_history = gru_model.fit(X_train, Y_train, epochs=200, batch_size=32, validation_data=(X_valid, Y_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_history = cnn_model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_data=(X_valid, Y_valid))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Results\nplt.figure(figsize=(12, 8))\nplt.plot(cnn_history.history['accuracy'])\nplt.plot(lstm_history.history['accuracy'])\nplt.plot(gru_history.history['accuracy'])\nplt.legend(['CNN Accuracy', 'LSTM Accuracy', 'GRU Accuracy'])\nplt.show()\n\nplt.figure(figsize=(12, 8))\nplt.plot(cnn_history.history['val_accuracy'])\nplt.plot(lstm_history.history['val_accuracy'])\nplt.plot(gru_history.history['val_accuracy'])\nplt.legend(['CNN Val Accuracy', 'LSTM Val Accuracy', 'GRU Val Accuracy'])\nplt.show()\n\nplt.figure(figsize=(12, 8))\nplt.plot(cnn_history.history['loss'])\nplt.plot(lstm_history.history['loss'])\nplt.plot(gru_history.history['loss'])\nplt.legend(['CNN Loss', 'LSTM Loss', 'GRU Loss'])\nplt.show()\n\nplt.figure(figsize=(12, 8))\nplt.plot(cnn_history.history['val_loss'])\nplt.plot(lstm_history.history['val_loss'])\nplt.plot(gru_history.history['val_loss'])\nplt.legend(['CNN Val Loss', 'LSTM Val Loss', 'GRU Val Loss'])\nplt.show()\n\n# Evaluate Models on Test Data\ncnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test, Y_test, verbose=2)\nlstm_test_loss, lstm_test_acc = lstm_model.evaluate(X_test, Y_test, verbose=2)\ngru_test_loss, gru_test_acc = gru_model.evaluate(X_test, Y_test, verbose=2)\n\nprint('CNN Test Accuracy:', cnn_test_acc)\nprint('LSTM Test Accuracy:', lstm_test_acc)\nprint('GRU Test Accuracy:', gru_test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ncnn_predictions = cnn_model.predict(X_test)\nlstm_predictions = lstm_model.predict(X_test)\ngru_predictions = gru_model.predict(X_test)\n\n# Combine predictions using majority voting\nensemble_predictions = np.argmax(cnn_predictions + lstm_predictions, axis=1)\n\n# Calculate accuracy of the ensemble model\nensemble_accuracy = np.mean(ensemble_predictions == np.argmax(Y_test, axis=1))\nprint(f\"Ensemble Model Accuracy: {ensemble_accuracy}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}